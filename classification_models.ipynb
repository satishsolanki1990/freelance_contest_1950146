{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "asian-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# import xgboost as xgb\n",
    "#XGBClassifier \n",
    "# error in installation\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "southeast-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set warning off\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-popularity",
   "metadata": {},
   "source": [
    "# Perform logistic on clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "conventional-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data TODO\n",
    "def read_data(data_size=10000, split_ratio=0.15):\n",
    "    \n",
    "    x=pd.read_csv('./model_data/features_clean.csv').to_numpy()\n",
    "    y=pd.read_csv('./model_data/labels_clean.csv').to_numpy()\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=split_ratio, random_state=1)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-launch",
   "metadata": {},
   "source": [
    "### Precision, Recall , TP, TN, FP and FN\n",
    "\n",
    "Precision attempts to answer the following question:\n",
    "What proportion of positive identifications was actually correct?\n",
    "\n",
    "Recall attempts to answer the following question:\n",
    "What proportion of actual positives was identified correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "reflected-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(model,x,y):\n",
    "    y_pred = model.predict(x)\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0 \n",
    "    FN = 0\n",
    "    for i in range(len(x)):\n",
    "        if y[i] == 1: # positive\n",
    "            if y_pred[i] == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else: # negative\n",
    "            if y_pred[i] == 1:\n",
    "                FP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "    \n",
    "    precision_pos = TP / (TP+FP)\n",
    "    \n",
    "    precision_neg = TN / (TN+FN)\n",
    "    \n",
    "    recall_pos = TP / (TP+FN)\n",
    "    \n",
    "    recall_neg = TN / (TN+FP)\n",
    "    \n",
    "    accuracy = (TN+TP) / (TN+TP+FP+FN)\n",
    "    \n",
    "    return precision_pos,precision_neg,recall_pos,recall_neg,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test=read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "macro-highway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score =  0.9520831819301011\n",
      "test score =  0.95161468769592\n"
     ]
    }
   ],
   "source": [
    "# fit logistic regression\n",
    "logit_model = LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "print('training score = ',logit_model.score(x_train, y_train))\n",
    "print('test score = ',logit_model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "awful-durham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** LOGISTIC REGRESSION *************\n",
      "Testing precisions and recalls\n",
      "precision on 1 =  0.9985525534441805\n",
      "precision on 0 =  0.9052674012362268\n",
      "Recall on 1 =  0.9123431671753137\n",
      "Recall on 0 =  0.9984236904505281\n",
      "accuracy =  0.95161468769592\n"
     ]
    }
   ],
   "source": [
    "precision_pos,precision_neg,recall_pos,recall_neg,accuracy = precision_recall(logit_model,x_test, y_test)\n",
    "\n",
    "print('*********** LOGISTIC REGRESSION *************')\n",
    "print('Testing precisions and recalls')\n",
    "print('precision on 1 = ',precision_pos)\n",
    "print('precision on 0 = ',precision_neg)\n",
    "print('Recall on 1 = ',recall_pos)\n",
    "print('Recall on 0 = ',recall_neg)\n",
    "print('accuracy = ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-plasma",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "tight-beijing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score =  0.9534314390122471\n",
      "test score =  0.9528624288541679\n"
     ]
    }
   ],
   "source": [
    "DT_model = DecisionTreeClassifier().fit(x_train, y_train)\n",
    "\n",
    "print('training score = ',DT_model.score(x_train, y_train))\n",
    "print('test score = ',DT_model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "informative-silly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** DECISION TREE *************\n",
      "Testing precisions and recalls\n",
      "precision on 1 =  1.0\n",
      "precision on 0 =  0.9063534123795685\n",
      "Recall on 1 =  0.9133152481067028\n",
      "Recall on 0 =  1.0\n",
      "accuracy =  0.9528624288541679\n"
     ]
    }
   ],
   "source": [
    "precision_pos,precision_neg,recall_pos,recall_neg,accuracy = precision_recall(DT_model,x_test, y_test)\n",
    "\n",
    "print('*********** DECISION TREE *************')\n",
    "print('Testing precisions and recalls')\n",
    "print('precision on 1 = ',precision_pos)\n",
    "print('precision on 0 = ',precision_neg)\n",
    "print('Recall on 1 = ',recall_pos)\n",
    "print('Recall on 0 = ',recall_neg)\n",
    "print('accuracy = ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-offset",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
